# 过拟合
- 如果模型过于复杂，它会把训练数据里的噪声和随机波动都学进去，而不是学习数据背后真正的规律。这会导致模型在训练集上误差很低，但在新数据（测试集）上表现很差。
- 过拟合在线性回归中是什么样的？
通常表现为某些特征的权重 w 变得非常大。这使得模型对这些特征的微小变化极为敏感，失去了泛化能力。
#  L2 正则化项 (L2 Regularization Term)
- 解决过拟合问题
- 解决方法：增加惩罚项：
为了防止权重 w 变得过大，我们在原来的成本函数（衡量预测误差）后面，增加了一个“惩罚项”。
![L2 Regularization](.\images\image.png)

# 训练集 验证集 测试集
- **训练集 (Training Set)**  
作用： 模型直接从这些数据中学习，通过反向传播不断更新权重 w 和偏置 b，以最小化损失函数。

- **验证集 (Validation Set)**  
作用： 不参与模型的权重更新。它的唯一作用是：在训练过程中，定期评估不同“学习策略”（即超参数）下的模型表现如何。
- **测试集 (Test Set)**  
作用： 完全独立的数据，只在模型最终选定后使用一次，用来评估模型的最终泛化能力。

# 验证集的两种方法
## 简单留出验证集 (Hold-out Validation) 
这是在深度学习中最常见、最实用的方法，因为它的计算成本相对较低。实现步骤如下：
1. **数据划分**  
在项目开始时，一次性将全部数据划分为三部分：训练集、验证集、测试集。
常见的比例是 70% / 15% / 15% 或 80% / 10% / 10%。如果数据量巨大（百万级以上），验证集和测试集的比例可以更小。
2. **超参数调优循环**  
你想比较几组不同的超参数，比如：  
模型A： 学习率=0.01，2个隐藏层，使用Adam优化器。
模型B： 学习率=0.001，3个隐藏层，使用Adam优化器。
模型C： 学习率=0.01，2个隐藏层，使用SGD优化器。
对每一个模型配置，执行以下操作：  
- 在训练集上训练模型。
- 每训练一个或几个 epoch（轮次），就在验证集上评估一次模型的性能（如准确率、损失值）。
- 记录下该模型在验证集上的最佳表现。同时，这也是早停法 (Early Stopping) 的依据：如果模型在验证集上的表现连续多轮不再提升，就可以提前停止训练，防止过拟合。
3. **选择最佳模型**
所有模型（A, B, C）都跑完后，比较它们各自在验证集上的最佳表现。
假设模型B在验证集上的准确率最高，那么你就认为 学习率=0.001，3个隐藏层，使用Adam优化器 是最佳的超参数组合。
4. 最终评估：
将选出的最佳模型（模型B），在从未见过的测试集上进行一次最终的评估。
这个成绩，才是你可以对外报告的、代表模型真实泛化能力的成绩。
## K-折交叉验证 (K-Fold Cross-Validation) - 更可靠但成本高
这是传统机器学习中非常标准的方法。在深度学习中，由于训练耗时太长，它通常只在数据集较小或对评估结果的可靠性要求极高的场景下使用。实现步骤如下：  
1. **数据划分**  
首先，将测试集完全分出去，锁起来不用。将剩下的数据（训练集 + 验证集）合并，然后把它平均分成 K 份（比如 K=5 或 K=10）。
2. **K-折交叉验证循环**  
你想测试一组超参数（比如上面提到的模型A的配置）。
进行 K 次训练和验证的循环：  
第1轮： 用第1份数据做验证集，剩下的 K-1 份做训练集。训练模型，记录在第1份验证集上的分数。  
第2轮： 用第2份数据做验证集，剩下的 K-1 份做训练集。训练模型，记录在第2份验证集上的分数。  
...  
第K轮： 用第K份数据做验证集，剩下的 K-1 份做训练集。训练模型，记录在第K份验证集上的分数。
3. **计算平均性能**  
将 K 次得到的验证分数（比如准确率）求一个平均值。这个平均值，就是模型A这套超参数配置的最终评估分数。它比单次验证的结果更稳定、更可靠，因为它利用了所有数据进行验证。
4. **选择最佳模型**  
对你想要尝试的每一套超参数组合（模型A, B, C...），都完整地重复一遍上面的步骤2和3。最后，比较哪一套超参数组合得到的平均验证分数最高。
5. **最终评估**  
选定最佳的超参数组合后，通常会用这套配置在全部的非测试集数据上重新训练一个最终模型。然后用这个最终模型在被锁起来的测试集上进行评估。

# 正则化λ如何防止过拟合
λ 是一个控制模型复杂度的“惩罚旋钮”，通过限制模型权重的大小来防止模型学得太“死”（过拟合），从而提升其在未知数据上的表现。 
核心机制是通过改变优化算法（如梯度下降）的数学计算过程来实现的。  
简单来说，λ 通过修改成本函数 (Cost Function)，进而改变了梯度 (Gradient)，最终影响了每一次权重更新 (Weight Update) 的计算，从而“逼迫”权重变小。  
1. **回顾没有 λ 时的梯度下降**  
    在没有正则化时，我们的目标是最小化误差成本 J_original：  
   - **成本函数:** J_original = (1/2m) * Σ(f(x) - y)²
   - **权重更新规则:** w_j := w_j - α * (∂J_original / ∂w_j)  

    这里的 ∂J_original / ∂w_j 是成本函数对权重 w_j 的偏导数（即梯度）。这个梯度的作用是告诉我们“w_j 应该朝哪个方向更新才能让误差下降得最快”。

2. **引入 λ 之后的成本函数和梯度**
现在，把正则化项加进来，成本函数变成了 J_reg：  
**新的成本函数:** J_reg = J_original + (λ/2m) * Σ(w_j)²  
为了进行梯度下降，我们必须计算这个新成本函数的梯度：  
∂J_reg / ∂w_j = ∂/∂w_j [ J_original + (λ/2m) * Σ(w_j)² ]  
根据求导法则，我们可以把它拆开：  
∂J_reg / ∂w_j = (∂J_original / ∂w_j) + ∂/∂w_j [ (λ/2m) * Σ(w_j)² ]  
我们来计算后面这一项的偏导数：  
∂/∂w_j [ (λ/2m) * w_j² ] = (λ/2m) * 2 * w_j = (λ/m) * w_j  
所以，新的梯度就变成了：  
∂J_reg / ∂w_j = (∂J_original / ∂w_j) + (λ/m) * w_j  
1. **观察新的权重更新规则（核心步骤）**  
现在，把这个新的梯度代入到权重更新规则中：  
w_j := w_j - α * [ (∂J_original / ∂w_j) + (λ/m) * w_j ]  
让我们把括号展开，看得更清楚一点：  
w_j := w_j - α * (∂J_original / ∂w_j) - (α * λ / m) * w_j  
对项数进行重新组合： 
w_j := w_j * (1 - α * λ / m) - α * (∂J_original / ∂w_j)  
1. 解读这个公式，在每一次的权重更新中，都发生了两件事：  
   - **权重衰减 (Weight Decay):**   
    w_j 首先被乘以一个 (1 - α * λ / m)。因为 α, λ, m 都是正数，所以这个因子是一个小于1的数。这就意味着，在做任何其他更新之前，w_j 会先被按比例缩小一点，向0靠近。λ 越大，这个缩小的比例就越大！ 这就是“惩罚”的具体体现。这个“惩罚”的力度由 λ 决定。然后，你再根据当前的训练误差，进行常规的调整去更好地拟合数据。
   - **常规更新:**  
    然后，像以前一样，再减去一个常规的梯度项 α * (∂J_original / ∂w_j) 来努力拟合数据。